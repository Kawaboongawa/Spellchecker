################################################################################
################################################################################

   _____            _ _  _____ _               _
  / ____|          | | |/ ____| |             | |
 | (___  _ __   ___| | | |    | |__   ___  ___| | _____ _ __
  \___ \| '_ \ / _ \ | | |    | '_ \ / _ \/ __| |/ / _ \ '__|
  ____) | |_) |  __/ | | |____| | | |  __/ (__|   <  __/ |
 |_____/| .__/ \___|_|_|\_____|_| |_|\___|\___|_|\_\___|_|
        | |
        |_|

################################################################################
################################################################################

VERSION :


                        Last Update done the 31/08/2017
                                 Spellchecker v1.0


AUTHORS :


                        LUGAND Jérémy jeremy.lugand@epita.fr
                        CETRE Cyril   cyril.cetre@epita.fr


PREVIEW :


This is a C language spell checker building first a disk written
dictonnary an then using it to give every word that matches
the request within a given distance of Damerau-Levenshtein.
This project was written for an EPITA school project.


REQUIREMENT :


This project is available on both OSX and LINUX operating system.
You will only need a version of gcc and gcc-7 on macos.


BUILD :


To build the project run the make command
just as shown in the following in the root directory of the project :

$> make

This should generate two differents binaries : TextMiningCompiler and
TextMiningCompiler.

To ensure that everything is working properly you can run our testcase that
compare to the reference given by the teacher. you can do so by typing :

$> make test

To clean binaries & trash files generated by the projet, you can simply type:

$> make clean


THE COMPILER :


usage :
$> ./ref/osx/TextMiningCompiler /path/to/word/freq.txt /path/to/output/dict.bin

The binary will take a text file as first argument and will generate a
dictionary with the name of the second argument as output. The text file
must respect a proper syntax, wich is the word, followed by at least one
space and followed by its frequency and a linefeed. this is an example
of input :

$> cat -e example_word.txt
this     705$
was      695$
a        2014$
cool     758$
project  810$
to       69619$
do       5349$


THE REQUEST APPLICATION:


usage :
$> ./TextMiningApp /path/to/compiled/dict.bin
approx 1 this
approx 0 is
approx 2 an
approx 6 example
$> echo "approx 2 anotherone" | ./TextMiningApp /path/to/compiled/dict.bin
$> ./TextMiningApp /path/to/compiled/dict.bin < /path/to/file_with_request.txt

This binary will take the dictionnary compiled by the compiler as first argument
and will read stdin. The input must have the format given above.
the number given is the maximal distance that we are looking for. A distance
of 0 means that we are looking for the exact word. Be careful that greater
is the distance, greater is the time taken to process the request.
The output result is given in JSON format.


QUESTIONS :


1) We use a trie which is used to store every words in the dictonnary
and to find quickly the word we are looking for during the search.
We have also optimized this trie to a radix tree which is basically
a space-optimized trie that remove the internal nodes which
are not terminal, wich means this node is not the last letter of a word.
Every nodes contains aswell several metadata such as its numbers
of childrens or the frequence of the word if this is its last letter.
A radix tree also increase search efficiency as it remove several nodes
and memory usage.

For the request search, we use an optimized way to go through the radix tree
with levenshtein distance. We keep in memory only the two previous rows as
this is the only data we need to go through the tree applying
Damerau-Levenshtein distance. As we chose C programming, we did our best to
keep it simple to get as much performances as we could with a relatively simple
design.

2) As we progressed through the implementation of our spell checker, several
kind of tests were made to ensure that the program is working as expected and
fullfilling the subject's requirement.

The test suite is our main tool to test the software. It ensures that the output
is exactly the one of the reference's binary, comparing the two output. It
compares also the performances and gives a proper ratio between the two,
expressed in requests per seconds.

In addition to the test suite several tests we made individually. For example we
tested the output of the tree, the printing and sorting functions individually,
the software's RAM usage, very high exepected distances, and general
comparisons between ref and our spellchecker output.

3) We tried with distance superiors than the word's length and the software
doesn't break but seems to print some values that doesn't seems reliable. Our
software is case sensitive and doesn't handle this kind of errors (which
means "Word" will not propose "word" with a distance of 1).


4) As mentionned before, we chose to implement a radix tree as data stucture.
This was the best compromise between binary size (which revealed to
be quite acceptable) and the information that we get during the search.
It is juste a trie that is compressed with nodes that can handle more than
one letter to remove useless internal nodes that are not terminals.

We chose this data structure because we saw few online levenshtein
implementations that were using a trie and were getting great results.
We simply adapted this to a Damerau-levenshtein implementation and
a radix tree instead of a simple trie.
 
5) 

6) Boosting our program performance has been a huge factor in our choice of
implementation. First, we chose the radix tree and a damerau-levenshtei=n
specific to trie. We chose aswell C langage to keep a good language effiency.
We even wrote the min3 function that is call a very numerous time in assembly
language to improve performances. We tried aswell to remove as much useless
program part that we could to reduce the bottleneck function search_rec as
much as possible.

To improve theses performances again and reach a level competitive with the
given refs, the only way seems to use state-of-the art algorithm that we
will shortly discuss in the next question.

7)